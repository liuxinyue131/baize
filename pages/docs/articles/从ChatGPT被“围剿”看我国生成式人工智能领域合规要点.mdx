# 从ChatGPT被“围剿”看我国生成式人工智能领域合规要点
## 正文
来源：泰和泰律师作者：兰珊  泰和泰律师事务所律师，业务领域：数字安全、知识产权、民商事争议解决。引言ChatGPT自2023年3月推出GPT-4以来，可以说吸引了全球各界的关注，但在3月31日意大利数据保护局（GPDP）打响全球“围剿”的第一枪以来，截止目前已有7个国家政府、28家欧美大学明令禁止使用ChatGPT；此外还有加拿大、法国、爱尔兰、德国等国家表示，会对其加强监管，不排除在未来会对其进行封禁。除了各国政府给出的理由（不符合GDPR、错误信息的传播、泄漏个人信息、隐私、未设立检查用户年龄的机制）及大学给出理由（不是学生原创，用它写论文，是剽窃、学术不端），ChatGPT遭“围剿”还有没有别的理由？笔者认为，当然有。全球“围剿”ChatGPT的现象其实质是，各国为了维护各国自身在数字经济时代的利益，防止作为本国重要生成要素的数据资源的流失，于是纷纷拿起法律的武器，开始完善本国生成式人工智能（AI-Generated Content，以下简称“AIGC”）领域的法律体系，以帮助本国在新一轮技术革命中抢占领先地位。鉴于此，我国监管机构亦有所应对，例如中国支付清算协会4月10日发布《关于支付行业从业人员谨慎使用ChatGPT等工具的倡议》；网信办4月11日公布的《生成式人工智能服务管理办法（征求意见稿）》，更是标志着我国生成式人工智能领域的法律法规体系已见雏形。一、 ChatGPT及其带来的风险1. 什么是ChatGPT？ChatGPT是一种人工智能深度强化学习模型，属于AIGC，其是一种基于自然语言的模型（NLP），可大幅提高AI的思考力，并在人机对话中提升准确性和可控性。其中，深度强化学习（DRL）=深度学习（DL）+强化学习（RL）。ChatGPT与以往模型相比，其成功的关键因素：有GPT-1、GPT-2、GPT-3为GPT-4进行预训练，且预训练数据经过人工标注，使得GPT-4数据质量更高；其是一种基于自然语言的模型，其模型中的强化学习的反馈信号来自于人类；算法参数巨大达1750亿等。2. ChatGPT带来的风险根据其技术原理及我国总体国家安全观的内容，其可能涉及到的风险领域有：政治安全、军事安全、经济安全、社会安全、文化安全、数字安全、资源安全、海外利益安全等；但笔者认为，其中最为重要的有两方面：■ 对安全的威胁，包括对军事安全、数字安全的威胁；■ 对现有制度的冲击，包括对知识产权、个人信息、隐私、消费者保护、反不正当竞争等领域的冲击。其中争议最大的要属AI生成的事物怎么保护，由于该问题属于近期热点，亦有不少文章对其进行讨论，笔者在此不做讨论；本文将重点介绍其它几个与AIGC强相关的领域，以望给予相关领域经营者、投资者些许指引。二、 生成式人工智能领域强相关法律领域1. 军事安全领域从技术上来看，ChatGPT有做威胁情报分析的天然优势、可能被间谍组织用于情报传递活动等风险；因此，AIGC领域的经营者、投资者应关注军事安全领域的法律法规。其中，值得关注的是，即将于本月召开的十四届全国人大常委会第二次会议将对《反间谍法》修订草案进行第三次审议，或将有相关的规定出台。2. 数字安全领域数字安全作为集网络安全、信息安全、数据安全、隐私保护、元宇宙安全、数字身份、原生安全于一体的新提法，其将过去网络、数据、隐私保护等领域的法律法规均涵盖其中。下图是其基本框架：原图载于：云安全联盟大中华区《2022全球数字安全报告》就该领域而言，除了各国政府及Open AI自己的《安全路径报告》所提到的理由（不符合GDPR、错误信息的传播、泄漏个人信息、隐私、未设立检查用户年龄的机制），在数据作为生成要素的背景下，AIGC还和以下领域息息相关：■ 数据安全及数据跨境安全有学者提到，不知道数据领域保护的利益是什么？笔者认为，随着大数据技术的发展，数据的价值并不是一成不变，而是随着时间、技术、数据量、结合数据种类等因素变化而发生变化；同样的数据，不同的算法，可能有不同的结果。具体到数据的数量来看，单个的数据可能并不重要，但当其达到一定数量级时，往往威胁到国家安全。具体到ChatGPT中来看，许多人不理解为何国家会禁止其使用，除了用户输入的数据本身是一种资源外，还有用户对其生成内容的评价反馈，恰恰也是ChatGPT成功的关键因素之一。为了让本国的数据资源不流失、本国类ChatGPT模型的更好发展，各国禁止本国用户使用他国类ChatGPT模型，显然是对本国利益的保护。因此，笔者认为，数据领域保护的利益，其最根本的利益就是国家利益。正是由于数据价值的此种特点，数据安全领域的法律法规将是相关领域经营者、投资者应关注的首要领域。■ 网络安全领域值得大家注意的是，由于ChatGPT生成的事物，不再局限于图片、文字，还有代码，那么ChatGPT还存在生成恶意代码、恶意文本，被用于网络攻击的风险；而我国现有网络安全审查制度针对的是企业，未涉个人；而ChatGPT的用户多为个人，而普通个人对该类文件不具识别能力，因此其可能在数字安全各个领域都存在风险。虽然数字安全的提法是新的，但其实际内容却不是新的，近期除了《商用密码管理条例（修订草案）》通过，未有其它太大的修订，相关领域运营者、投资者注意遵守相关法律法规即可，笔者在此不再赘述。3. AIGC领域随着科技部4月4日公布的《科技伦理审查办法（试行）》和网信办4月11日公布的《生成式人工智能服务管理办法（征求意见稿）》，我国AIGC领域的法律法规体系已见雏形。主要有以下几个：其中，网信办4月11日公布的《生成式人工智能服务管理办法（征求意见稿）》，在《互联网信息服务算法推荐管理规定》、《具有舆论属性或社会动员能力的互联网信息服务安全评估规定》、《互联网信息服务深度合成管理规定》的基础上，对不得歧视义务、防止生成虚假信息义务、人工标注相关义务、信息公开义务、防范用户过分依赖或沉迷、个人信息保护义务、用户投诉接收处理机制等进行了细化；此外，还新增了几条规定：（1）要求AIGC提供者及技术支持者要对生成内容承担责任：利用AIGC产品提供聊天和文本、图像、声音生成等服务的组织和个人（以下称“提供者”），包括通过提供可编程接口等方式支持他人自行生成文本、图像、声音等，承担该产品生成内容生产者的责任（第5条）；（2）预训练数据、优化数据的合法性要求：提供者应当对AIGC产品的预训练数据、优化训练数据来源的合法性负责；提供者能够保证数据的真实性、准确性、客观性、多样性（第7条）；（3）不法内容处理机制：对于运行中发现、用户举报的不符合本办法要求的生成内容，除采取内容过滤等措施外，应在3个月内通过模型优化训练等方式防止再次生成（第15条）；（4）积极指导义务：提供者应当指导用户科学认识和理性使用AIGC生成的内容（第18条）。由于《科技伦理审查办法（试行）》《生成式人工智能服务管理办法（征求意见稿）》还处在征求意见的阶段，且已经有不少学者对其部分内容表达了修改意见；而本文的重点在于给各位读者提供合规指引，故在此不对相关规定内容的合理性进行讨论。三、AIGC合规要点根据上文所述，由于AIGC的特点，其涉及的法律领域较多，但笔者经分析后认为，其合规要点主要集中在：数据、算法模型、生成内容、运营行为4大方面。其合规要点思维导图如下：四、可能涉及到的许可、评估、审查细心的读者从上面的思维导图就可以看到，AIGC领域的运营者，在运营中可能涉及到的许可、评估、审查繁多，为了让相关运营者、投资者有更为清晰的认识，笔者对其可能涉及的许可、评估、审查进行了梳理：结语在我国建设数字强国的战略背景下，2023年3月10日，十四届全国人大一次会议表决通过了关于国务院机构改革方案的决定，批准了组建国家数据局，可见我国发展数字经济的决心。鉴于此，即使火出天际的ChatGPT被全球“围剿”，其表现出来的强大功能仍确定了AIGC领域未来几年在各国重点发展领域名单中的地位。就我国来看，国家数据局的组建，除了要解决过去数字安全领域“九龙治水”的问题，可能还会在AIGC领域大展拳脚；为了赶超ChatGPT，国家数据局或会整合国内各部门、大厂的资源，打造国有的类ChatGPT模型，我国或将掀起一股AIGC研发、投资热。然任何事物的发展都离不开法律的保驾护航，虽然随着科技部《科技伦理审查办法（试行）》和网信办《生成式人工智能服务管理办法（征求意见稿）》的公布，我国AIGC领域的法律法规体系已见雏形。但由于AIGC本身的技术特点、其所带来的风险及法律体系尚未达到成熟阶段等原因，相关领域的运营者、投资者在实际中除了根据现有的法律法规合规经营外，仍会遇到没有具体法律法规的情况，此时，相关领域的运营者、投资者应把握好底线思维（坚持以人为本、不威胁国家主权等原则）、本质思维（透过技术、商业模式，看到实质的创新点）、行业思维（尊重各个行业的基本逻辑），做好创新和发展的平衡，积极与监管机构、第三方机构、律师建立联系，形成良好的沟通机制，以期在AIGC的新风口中掌握主动权、立于不败之地。注：因篇幅限制，注释省略无讼小编：如果您觉得这篇文章还不错，欢迎转发分享、点赞收藏，您也可以在下方评论区留下自己的观点，和大家一起讨论。主编：靖力责编：梁萌实习编辑：许福玲审核：刘逸凡 王雅玉 陈丽娟